 
ğŸ—“ï¸ WEEK 2 â€” DAY-BY-DAY HANDS-ON GUIDE
ğŸŸ¦ DAY 1 â€” Understand ADF Concepts + Connect ADF to Your Data Lake

Goal: Learn ADF architecture + connect to your ADLS Gen2 from Week 1.

ğŸ“˜ Study (1.5 hrs)

Complete Module 1:

â€œIntroduction to Azure Data Factoryâ€
https://learn.microsoft.com/learn/modules/intro-to-azure-data-factory/

Focus on:

Pipelines

Activities

Linked Services

Datasets

Integration Runtime

Watch (optional but recommended):
ğŸ¥ Adam Marczak ADF overview â†’ https://youtu.be/-QFJjzFZUlU

ğŸ”§ Hands-On (2â€“3 hrs)

Open Azure Portal â†’ Create Data Factory

Name: adf-customer360-yourname

Version: V2

Region: same as your storage account

In ADF Studio â†’ Create Linked Service:

Azure Data Lake Storage Gen2

Authentication: Managed Identity (prefer) or Account Key (for learning only)

Test connection

Verify ADF can browse your storage containers raw/, clean/, curated/.

ğŸ“ Files to Create in Repo
project/week2-adf/linked-services.md
project/week2-adf/screenshots/


Add screenshot:

Linked Service test successful

ğŸŸ¦ DAY 2 â€” Build the First Ingestion Pipeline (Static Copy Activity)

Goal: Create a pipeline that copies a known file (customers.csv) â†’ ADLS raw/.

ğŸ“˜ Study (1â€“1.5 hrs)

Complete Learn Module:

â€œBuild your first data factory and pipelineâ€
https://learn.microsoft.com/learn/modules/build-your-first-data-factory/

ğŸ”§ Hands-On (2.5â€“3 hrs)

In ADF, create pipeline: pl_ingest_customers

Add Copy Data activity

Create Dataset (Source):

Type: Binary or DelimitedText

Point to your local file or sample dataset

Create Dataset (Sink):

ADLS Gen2

Folder: /raw/customers/

Publish and run the pipeline

Confirm in ADLS that the file appears

ğŸ“ Repo Work

Add:

/project/week2-adf/screenshots/run1-success.png
/project/week2-adf/pl_ingest_customers_notes.md
